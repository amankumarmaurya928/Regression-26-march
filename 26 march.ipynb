{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb45baf8-0bc2-4a71-a902-a59984f740fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Simple linear regression has only one x and one y variable.\\n   Multiple linear regression has one y and two or more x variables. \\n   Example simple linear:\\n     You are a social researcher interested in the relationship between income and happiness. \\n     You survey 500 people whose incomes range from 15k to 75k and ask them to rank their happiness on a scale from 1 to 10.\\n   Example multiple linear:\\n     A researcher decides to study students’ performance from a school over a period of time.\\n     '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1\n",
    "'''Simple linear regression has only one x and one y variable.\n",
    "   Multiple linear regression has one y and two or more x variables. \n",
    "   Example simple linear:\n",
    "     You are a social researcher interested in the relationship between income and happiness. \n",
    "     You survey 500 people whose incomes range from 15k to 75k and ask them to rank their happiness on a scale from 1 to 10.\n",
    "   Example multiple linear:\n",
    "     A researcher decides to study students’ performance from a school over a period of time.\n",
    "     '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51f4f8d0-58dc-4025-9804-409b09a55bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are primarily five assumptions of linear regression. \\n   They are:\\n1. There is a linear relationship between the predictors (x) and the outcome (y)\\n2. Predictors (x) are independent and observed with negligible error\\n3. Residual Errors have a mean value of zero\\n4. Residual Errors have constant variance\\n5. Residual Errors are independent from each other and predictors (x)\\n\\nWe can check the linearity of the data by looking at the Residual vs Fitted plot.\\nIdeally, this plot would not have a pattern where the red line (lowes smoother) is approximately horizontal at zero.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2\n",
    "'''There are primarily five assumptions of linear regression. \n",
    "   They are:\n",
    "1. There is a linear relationship between the predictors (x) and the outcome (y)\n",
    "2. Predictors (x) are independent and observed with negligible error\n",
    "3. Residual Errors have a mean value of zero\n",
    "4. Residual Errors have constant variance\n",
    "5. Residual Errors are independent from each other and predictors (x)\n",
    "\n",
    "We can check the linearity of the data by looking at the Residual vs Fitted plot.\n",
    "Ideally, this plot would not have a pattern where the red line (lowes smoother) is approximately horizontal at zero.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e04c58c-11ca-445f-8bf1-dbe7870b11c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To interpret the slope of the line, identify the variables in the situation. Since slope is change in y divided by change\\nin x, divide the y-variable by the x-variable to get the units for the slope. Then, write a sentence to connect this value and\\nits units back to the scenario in the problem.\\nExample:\\nData is collected on the cost of flights from Baltimore, Maryland, to different destinations.\\n\\n\\nthe slope and intercept of the graph provide useful information about the initial conditions and rate of change of what is\\nbeing studied. First, the slope of a line is a measure of its steepness. In a line, slope is a ratio of the change in one\\nvariable to the change in the other. Usually, this refers to the change in y for each unit change in x, but sometimes other \\nvariables may be used.\\nThe formula for slope is the change in y over the change in x. The triangle is the Greek letter delta, which represents change.\\n\\nA red line in the 1st quadrant of a graph. The rise and run are shown in blue and labeled delta y and delta x respectively.\\nSlope is usually represented by the variable \\nm  =  Δy/Δx  =  (y2−y1)/(x2−x1)  = change in y/change in x\\n\\nThe intercept refers to the y-intercept, which is where the line intersects the y-axis. \\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3\n",
    "'''To interpret the slope of the line, identify the variables in the situation. Since slope is change in y divided by change\n",
    "in x, divide the y-variable by the x-variable to get the units for the slope. Then, write a sentence to connect this value and\n",
    "its units back to the scenario in the problem.\n",
    "Example:\n",
    "Data is collected on the cost of flights from Baltimore, Maryland, to different destinations.\n",
    "\n",
    "\n",
    "the slope and intercept of the graph provide useful information about the initial conditions and rate of change of what is\n",
    "being studied. First, the slope of a line is a measure of its steepness. In a line, slope is a ratio of the change in one\n",
    "variable to the change in the other. Usually, this refers to the change in y for each unit change in x, but sometimes other \n",
    "variables may be used.\n",
    "The formula for slope is the change in y over the change in x. The triangle is the Greek letter delta, which represents change.\n",
    "\n",
    "A red line in the 1st quadrant of a graph. The rise and run are shown in blue and labeled delta y and delta x respectively.\n",
    "Slope is usually represented by the variable \n",
    "m  =  Δy/Δx  =  (y2−y1)/(x2−x1)  = change in y/change in x\n",
    "\n",
    "The intercept refers to the y-intercept, which is where the line intersects the y-axis. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d251782c-4b18-4b93-b1a3-9fd767f241c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gradient descent is an optimization algorithm which is commonly-used to train machine learning models and neural networks.\\n   Training data helps these models learn over time, and the cost function within gradient descent specifically acts as a\\n   barometer, gauging its accuracy with each iteration of parameter updates.\\n     Example: minimizing the Residual Sum of Squares in Linear Regression.\\n     '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4\n",
    "'''Gradient descent is an optimization algorithm which is commonly-used to train machine learning models and neural networks.\n",
    "   Training data helps these models learn over time, and the cost function within gradient descent specifically acts as a\n",
    "   barometer, gauging its accuracy with each iteration of parameter updates.\n",
    "     Example: minimizing the Residual Sum of Squares in Linear Regression.\n",
    "     '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39c3409b-ab1e-4eb9-a68e-14f054cf7db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Multiple linear regression is a regression model that estimates the relationship between a quantitative dependent variable\\n   and two or more independent variables using a straight line.\\n   \\n   while simple linear regression has only one independent variable.\\n   '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5\n",
    "'''Multiple linear regression is a regression model that estimates the relationship between a quantitative dependent variable\n",
    "   and two or more independent variables using a straight line.\n",
    "   \n",
    "   while simple linear regression has only one independent variable.\n",
    "   '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aac109cf-5d31-4299-bc51-9bc8f745463f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Multicollinearity exists whenever an independent variable is highly correlated with one or more of the other independent\\n   variables in a multiple regression equation.\\n   Multicollinearity is a problem because it will make the statistical inferences less reliable.\\n   Multicollinearity occurs when two or more independent variables in a data frame have a high correlation with one another \\n   in a regression model. This means that one independent variable can be predicted from another in a regression model.\\n   '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q6\n",
    "'''Multicollinearity exists whenever an independent variable is highly correlated with one or more of the other independent\n",
    "   variables in a multiple regression equation.\n",
    "   Multicollinearity is a problem because it will make the statistical inferences less reliable.\n",
    "   Multicollinearity occurs when two or more independent variables in a data frame have a high correlation with one another \n",
    "   in a regression model. This means that one independent variable can be predicted from another in a regression model.\n",
    "   '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e054394-e0a8-4257-ac1e-17614e03e9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Polynomial regression is a form of Linear regression where only due to the Non-linear relationship between dependent and\\n   independent variables, we add some polynomial terms to linear regression to convert it into Polynomial regression.\\n   \\n   Polynomial equations are generally solved with the hit and trial method. We put in the value of the independent variable \\n   and try to get the value of the expression equal to zero. In case of a linear equation, obtaining the value of the \\n   independent variable is simple. We solve the equation for the value of zero.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q7\n",
    "'''Polynomial regression is a form of Linear regression where only due to the Non-linear relationship between dependent and\n",
    "   independent variables, we add some polynomial terms to linear regression to convert it into Polynomial regression.\n",
    "   \n",
    "   Polynomial equations are generally solved with the hit and trial method. We put in the value of the independent variable \n",
    "   and try to get the value of the expression equal to zero. In case of a linear equation, obtaining the value of the \n",
    "   independent variable is simple. We solve the equation for the value of zero.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be3e9d3e-e286-42bb-8b4c-96d99e4e381a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Advantage – Polynomial Regression\\n The polynomial regression is flexible enough to get fitted in a vast range of curvatures. A broad range of functions can\\n easily fit under it. The polynomial regression offers the best approximation of the relationship between the two dependent\\n and independent variables.\\n Polynomial provides the best approximation of the relationship between the dependent and independent variable. \\n A Broad range of function can be fit under it. Polynomial basically fits a wide range of curvature.\\n\\nDisadvantages of Polynomial Regression\\n One or two outliers in the data might have a significant impact on the nonlinear analysis' outcomes. These are overly reliant\\n on outliers. Furthermore, there are fewer model validation methods for detecting outliers in nonlinear regression than there \\n are for linear regression.\\n \\n In polynomial regression the line of intrecept is not found so We solve the equation for the value of zero.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q8\n",
    "'''Advantage – Polynomial Regression\n",
    " The polynomial regression is flexible enough to get fitted in a vast range of curvatures. A broad range of functions can\n",
    " easily fit under it. The polynomial regression offers the best approximation of the relationship between the two dependent\n",
    " and independent variables.\n",
    " Polynomial provides the best approximation of the relationship between the dependent and independent variable. \n",
    " A Broad range of function can be fit under it. Polynomial basically fits a wide range of curvature.\n",
    "\n",
    "Disadvantages of Polynomial Regression\n",
    " One or two outliers in the data might have a significant impact on the nonlinear analysis' outcomes. These are overly reliant\n",
    " on outliers. Furthermore, there are fewer model validation methods for detecting outliers in nonlinear regression than there \n",
    " are for linear regression.\n",
    " \n",
    " In polynomial regression the line of intrecept is not found so We solve the equation for the value of zero.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c37c5d-4e98-4b14-8cf1-dd829a1b89ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
